{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./titanic/train.csv')\n",
    "test = pd.read_csv('./titanic/test.csv')\n",
    "test_ = test\n",
    "train = train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test = test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "# train = train.dropna(axis=0, how='any')\n",
    "# test = test.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  34.5      0      0   7.8292        Q\n",
       "1       3  female  47.0      1      0   7.0000        S\n",
       "2       2    male  62.0      0      0   9.6875        Q\n",
       "3       3    male  27.0      0      0   8.6625        S\n",
       "4       3  female  22.0      1      1  12.2875        S"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Sex'].replace(to_replace=dict(female=1, male=0), inplace=True)\n",
    "train['Embarked'].replace(to_replace=dict(Q=2,C=1, S=0), inplace=True)\n",
    "test['Sex'].replace(to_replace=dict(female=1, male=0), inplace=True)\n",
    "test['Embarked'].replace(to_replace=dict(Q=2,C=1, S=0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_dummies = pd.get_dummies(train, columns=[ 'Pclass', 'Embarked'])\n",
    "# test_dummies = pd.get_dummies(test, columns=[ 'Pclass', 'Embarked'])\n",
    "train_dummies = train\n",
    "test_dummies = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3    0  22.0      1      0   7.2500       0.0\n",
       "1         1       1    1  38.0      1      0  71.2833       1.0\n",
       "2         1       3    1  26.0      0      0   7.9250       0.0\n",
       "3         1       1    1  35.0      1      0  53.1000       0.0\n",
       "4         0       3    0  35.0      0      0   8.0500       0.0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0       3    0  34.5      0      0   7.8292         2\n",
       "1       3    1  47.0      1      0   7.0000         0\n",
       "2       2    0  62.0      0      0   9.6875         2\n",
       "3       3    0  27.0      0      0   8.6625         0\n",
       "4       3    1  22.0      1      1  12.2875         0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 7)\n",
      "(891, 7) (1309, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0       3    0  22.0      1      0   7.2500       0.0\n",
       "1       1    1  38.0      1      0  71.2833       1.0\n",
       "2       3    1  26.0      0      0   7.9250       0.0\n",
       "3       1    1  35.0      1      0  53.1000       0.0\n",
       "4       3    0  35.0      0      0   8.0500       0.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features\n",
    "# X_train = train_dummies.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "# X_test = test_dummies.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "X_train = train_dummies.drop(['Survived'], axis=1)\n",
    "print(X_train.shape)\n",
    "X_full = train_dummies.drop(['Survived'], axis=1)\n",
    "X_full = X_full.append(test_dummies)\n",
    "print(X_train.shape,X_full.shape)\n",
    "X_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract targets\n",
    "y_train = train_dummies['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill NA values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=True)\n",
    "imp.fit(X_full)\n",
    "X_full = imp.transform(X_full)\n",
    "X_train = imp.transform(X_train)\n",
    "X_test = imp.transform(test_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(copy=True, with_mean=False, with_std=True)\n",
    "scaler.fit(X_full)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.75653501  0.73601191  2.30894938  0.50228343  0.44103174  0.62267519\n",
      "  0.55473276]\n",
      "[ 0.99543457  0.99544176  1.0181976   1.12032114  0.86692458  0.92216386\n",
      "  0.94569426]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(X_train, axis = 0))\n",
    "print(np.var(X_train, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.58202142  0.          1.70830382 ...,  0.          0.14018029  0.        ]\n",
      " [ 1.19400714  2.08849241  2.95070659 ...,  0.          1.37827771\n",
      "   1.53123551]\n",
      " [ 3.58202142  2.08849241  2.01890451 ...,  0.          0.15323155  0.        ]\n",
      " ..., \n",
      " [ 3.58202142  2.08849241  2.32027552 ...,  2.31152519  0.45341072  0.        ]\n",
      " [ 1.19400714  0.          2.01890451 ...,  0.          0.58005636\n",
      "   1.53123551]\n",
      " [ 3.58202142  0.          2.48480555 ...,  0.          0.14984789\n",
      "   3.06247101]]\n",
      "[[ 3.58202142  0.          2.67893098 ...,  0.          0.15137924\n",
      "   3.06247101]\n",
      " [ 3.58202142  2.08849241  3.64955815 ...,  0.          0.13534648  0.        ]\n",
      " [ 2.38801428  0.          4.81431075 ...,  0.          0.18730987\n",
      "   3.06247101]\n",
      " ..., \n",
      " [ 3.58202142  0.          2.98953168 ...,  0.          0.14018029  0.        ]\n",
      " [ 3.58202142  0.          2.32027552 ...,  0.          0.15564846  0.        ]\n",
      " [ 3.58202142  0.          2.32027552 ...,  1.15576259  0.43230247\n",
      "   1.53123551]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, \n",
    "#                    fit_intercept=True, intercept_scaling=1, class_weight=None, \n",
    "#                    random_state=None, solver='liblinear', max_iter=100,\n",
    "#                    multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Оценка качества методом кроссвалидации\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_reg = LogisticRegression(verbose=0, intercept_scaling=1,n_jobs=1 ,dual=False , warm_start=False,random_state = 42, )\n",
    "\n",
    "#Подбор параметров по сетке\n",
    "param_grid_l2 = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'tol': [0.001, 0.01, 0.1, 1],\n",
    "    'solver': [ 'newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "    'max_iter': [10,50,100, 500, 1000, 5000, 10000],\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "param_grid_l1 = {\n",
    "    'penalty': ['l1'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'tol': [0.001, 0.01, 0.1, 1],\n",
    "    'solver': [  'liblinear'],\n",
    "    'max_iter': [10, 50 ,100, 500, 1000, 5000, 10000],\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(X_train, y_train, \n",
    "                                                                                    test_size = 0.25,\n",
    "                                                                                    random_state = 42)\n",
    "#кроссвалидация на 5 фолда - отложеная выборка 10%\n",
    "cv = cross_validation.StratifiedShuffleSplit(train_labels, n_iter = 4, test_size = 0.25, random_state = 42)\n",
    "\n",
    "grid_search_l2 = GridSearchCV(log_reg, param_grid_l2,scoring = 'accuracy', cv = cv )\n",
    "grid_search_l1 = GridSearchCV(log_reg, param_grid_l1,scoring = 'accuracy', cv = cv )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.8 s, sys: 237 ms, total: 24 s\n",
      "Wall time: 24.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(labels=[1 0 ..., 1 0], n_iter=4, test_size=0.25, random_state=42),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'tol': [0.001, 0.01, 0.1, 1], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'], 'max_iter': [10, 50, 100, 500, 1000, 5000, 10000], 'class_weight': [None, 'balanced']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_l2.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 s, sys: 46 ms, total: 3.97 s\n",
      "Wall time: 4.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(labels=[1 0 ..., 1 0], n_iter=4, test_size=0.25, random_state=42),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'tol': [0.001, 0.01, 0.1, 1], 'solver': ['liblinear'], 'max_iter': [10, 50, 100, 500, 1000, 5000, 10000], 'class_weight': [None, 'balanced']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_l1.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='sag', tol=0.01, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_l2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.01,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_l1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793413173653\n",
      "{'C': 0.01, 'class_weight': None, 'max_iter': 10, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_l2.best_score_)\n",
    "print(grid_search_l2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782934131737\n",
      "{'C': 1, 'class_weight': None, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_l1.best_score_)\n",
    "print(grid_search_l1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid_search_l2.best_estimator_.fit(X_train, y_train)\n",
    "# y_pred = grid_search_l2.best_estimator_.predict(X_test)\n",
    "\n",
    "grid_search_l1.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid_search_l1.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your submission scored  0.77033 без fit 0.76077 c cv на отложеной выборки 25% -0.77033- {'C': 1, 'class_weight': None, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001}\n",
    "# Your submission scored 0.77033 без fit 0.76077 - {'C': 10, 'class_weight': None, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
    "#Результаты при данной стратегии кроссвалидации при различных параметрах совпали и  близки к собсвенной оценке 0.799382716049\n",
    "# при размере отложеннной выборки в 30%  оценки сильнее разлицаются - но ресультаты немного лучше "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.35417321  0.65238812 -0.14772808 -0.11235065  0.0039124   0.17706887\n",
      "   0.09467578]]\n",
      "[[-0.82771281  1.27741314 -0.42833061 -0.31923402 -0.07120385  0.16220672\n",
      "   0.15646548]]\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_l2.best_estimator_.coef_)\n",
    "print(grid_search_l1.best_estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Оценка качества методом кроссвалидации\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(X_train, y_train, \n",
    "                                                                                    test_size = 0.2,\n",
    "                                                                                    random_state = 42)\n",
    "#кроссвалидация на 5 фолда - отложеная выборка 10%\n",
    "cv = cross_validation.StratifiedShuffleSplit(train_labels, n_iter = 10, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813692480359\n",
      "ExtraTreesClassifier(bootstrap=True, class_weight='balanced',\n",
      "           criterion='gini', max_depth=None, max_features='auto',\n",
      "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "           oob_score=True, random_state=42, verbose=0, warm_start=False)\n",
      "Log mean:0.7373588274445697, max:0.784, min:0.6538461538461539, std:0.03679409512212857\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n",
    "# random_forest = RandomForestClassifier(bootstrap=True, class_weight='balanced', criterion='gini',\n",
    "#             max_depth=13, max_features='sqrt', max_leaf_nodes=None,\n",
    "#             min_impurity_split=1e-07, min_samples_leaf=2,\n",
    "#             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "#             n_estimators=1500, n_jobs=-1, oob_score=False,\n",
    "#             random_state=42, verbose=0, warm_start=True)\n",
    "\n",
    "random_forest = ExtraTreesClassifier(\n",
    "    max_features='auto',\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "#     min_samples_split=2,\n",
    "#    class_weight={0: 0.7, 1: 0.3},\n",
    "    class_weight='balanced',\n",
    "#     min_weight_fraction_leaf=0.02,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(random_forest.oob_score_)\n",
    "print(random_forest)\n",
    "\n",
    "\n",
    "# clf_ext = ExtraTreesClassifier(\n",
    "#     max_features='auto',\n",
    "#     bootstrap=True,\n",
    "#     oob_score=True,\n",
    "\n",
    "rf_scoring = cross_validation.cross_val_score(random_forest, X_train, y_train, scoring = 'f1', cv = cv)\n",
    "print( 'Log mean:{}, max:{}, min:{}, std:{}'.format(rf_scoring.mean(), rf_scoring.max(), \n",
    "                                                   rf_scoring.min(), rf_scoring.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76077"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your submission scored - 0.78469 - оценка oob - 0.793490460157 \n",
    "#Пробовал подбирать параметры по сетке - параметров много считает долго и результат часто хуже параметров по умолчанию(максимальный результат - 0.78947)\n",
    "#возможно еще неочень подходит выбранная стратегия кросс валидации или нужно по другому готовить данные\n",
    "0.76077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as out:\n",
    "    out.write('PassengerId,Survived\\n')\n",
    "    for passenger, y in zip(test_['PassengerId'], y_pred):\n",
    "        out.write('%s,%s\\n' % (passenger, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sattarov-a/Documents/DEV/Python/NETOLOGY_DS/anaconda/envs/DS1/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from mlxtend.classifier import StackingClassifier, StackingCVClassifier\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GradientBoostingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f464598b7665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# clf1 = KNeighborsClassifier(n_neighbors=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m clf1 = GradientBoostingClassifier(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     n_estimators = 575,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     max_depth=13,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GradientBoostingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf1 = GradientBoostingClassifier(\n",
    "    random_state = 0,\n",
    "#     n_estimators = 575,\n",
    "#     max_depth=13,\n",
    "#     min_samples_leaf=2,\n",
    ")\n",
    "clf2 = RandomForestClassifier(\n",
    "    n_estimators=575,\n",
    "    max_depth=13,\n",
    "    min_samples_leaf=2,max_features = None,\n",
    "    random_state=0, n_jobs=-1, warm_start= True,verbose = 0 )\n",
    "clf3 = AdaBoostClassifier(    \n",
    "    n_estimators=575,\n",
    "    learning_rate=0.95)\n",
    "# clf4 = LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
    "#           intercept_scaling=1, max_iter=10, multi_class='ovr', n_jobs=1,\n",
    "#           penalty='l2', random_state=42, solver='sag', tol=0.01, verbose=0,\n",
    "#           warm_start=False)\n",
    "clf4 = svm.SVC(\n",
    "    #kernel= 'linear', C=0.025\n",
    ")\n",
    "clf5 = ExtraTreesClassifier(\n",
    "    n_estimators=575,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=3,max_features = 'auto',\n",
    "    random_state=0, n_jobs=-1, warm_start= True,verbose = 0 \n",
    "    )\n",
    "\n",
    "\n",
    "clf3 = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "\n",
    "lr = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2,clf3], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "print(' cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1,clf2,clf3, sclf], \n",
    "                      [ 'GradientBoostingClassifier',\n",
    "                       'Random Forest', \n",
    "                       'XGBClassifier',\n",
    "#                       'SVC ',\n",
    "#                       'ExtraTreesClassifier',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X_train, y_train, \n",
    "                                              cv=cv, scoring='log_loss')\n",
    "    print(\"f1: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sclf.fit(X_train, y_train)\n",
    "y_pred = sclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787 +/- 0.01 {'randomforestclassifier__n_estimators': 10}\n",
      "0.793 +/- 0.02 {'randomforestclassifier__n_estimators': 100}\n",
      "0.787 +/- 0.02 {'randomforestclassifier__n_estimators': 500}\n",
      "Best parameters: {'randomforestclassifier__n_estimators': 100}\n",
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {\n",
    "#          'randomforestclassifier__n_estimators': [10, 100, 500],\n",
    "#           'meta-logisticregression__C': [0.1, 1, 10.0],\n",
    "#          'meta-logisticregression__penalty':['l1','l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=sclf, \n",
    "                    param_grid=params, \n",
    "                    cv=cv,\n",
    "                    refit=True)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)\n",
    "grid.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767 +/- 0.03 {}\n",
      "Best parameters: {}\n",
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2,clf3], weights=[1,1,1])\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "#          'randomforestclassifier__n_estimators': [10, 100, 500],\n",
    "#           'meta-logisticregression__C': [0.1, 1, 10.0],\n",
    "#          'meta-logisticregression__penalty':['l1','l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, \n",
    "                    param_grid=params, \n",
    "                    cv=cv,\n",
    "                    refit=True, scoring='f1')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)\n",
    "\n",
    "grid.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97d865b16d14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Практикум по Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.1'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
